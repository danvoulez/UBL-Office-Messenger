//! Baseline Performance Tests
//! Establish and validate performance baselines

use anyhow::Result;
use std::time::{Duration, Instant};
use std::collections::HashMap;
use serde: :{Serialize, Deserialize};

mod common;
use common::*;

#[derive(Debug, Serialize, Deserialize)]
struct PerformanceBaseline {
    test_name: String,
    timestamp: String,
    metrics: HashMap<String, PerformanceMetric>,
}

#[derive(Debug, Serialize, Deserialize)]
struct PerformanceMetric {
    p50: Duration,
    p95: Duration,
    p99: Duration,
    avg: Duration,
    min: Duration,
    max: Duration,
    samples: usize,
}

#[tokio::test]
async fn test_baseline_message_send_performance() -> Result<()> {
    println!("üìä Measuring Message Send Performance Baseline");
    
    let ctx = setup_golden_run().await?;
    let bootstrap = ctx.ubl_client.bootstrap("T.UBL").await?;
    let conversation_id = bootstrap.conversations. first()
        .and_then(|c| c["id"]. as_str())
        .unwrap_or("conv_default")
        .to_string();
    
    let mut durations = Vec::new();
    let samples = 100;
    
    println!("Running {} samples...", samples);
    
    for i in 0..samples {
        let start = Instant::now();
        
        ctx.ubl_client.send_message(SendMessageRequest {
            conversation_id: conversation_id. clone(),
            content: format! ("Baseline test message {}", i),
            idempotency_key: Some(format!("baseline_msg_{}", i)),
        }).await?;
        
        let duration = start.elapsed();
        durations. push(duration);
        
        if i % 10 == 0 {
            print!(".");
            std::io::Write::flush(&mut std::io::stdout()).ok();
        }
        
        tokio::time::sleep(Duration:: from_millis(100)).await;
    }
    
    println!();
    
    let metric = calculate_metric(&durations);
    
    println!("\nüìà Message Send Performance:");
    println!("   p50: {:?}", metric.p50);
    println!("   p95: {:?}", metric. p95);
    println!("   p99: {:?}", metric.p99);
    println!("   avg: {:?}", metric.avg);
    println!("   min: {:?}", metric. min);
    println!("   max: {:?}", metric.max);
    
    // Validate against targets
    assert!(metric.p95 < Duration::from_millis(500),
        "p95 exceeds target: {:?}", metric. p95);
    assert!(metric.p99 < Duration::from_secs(1),
        "p99 exceeds target: {:? }", metric.p99);
    
    // Save baseline
    let mut metrics = HashMap::new();
    metrics.insert("message_send". to_string(), metric);
    
    let baseline = PerformanceBaseline {
        test_name: "message_send_baseline".to_string(),
        timestamp: chrono::Utc::now().to_rfc3339(),
        metrics,
    };
    
    save_baseline(&baseline)?;
    
    println!("‚úÖ Baseline established and saved");
    Ok(())
}

#[tokio::test]
async fn test_baseline_job_creation_performance() -> Result<()> {
    println!("üìä Measuring Job Creation Performance Baseline");
    
    let ctx = setup_golden_run().await?;
    let bootstrap = ctx. ubl_client.bootstrap("T.UBL").await?;
    let conversation_id = bootstrap.conversations.first()
        .and_then(|c| c["id"].as_str())
        .unwrap_or("conv_default")
        .to_string();
    
    let mut durations = Vec::new();
    let samples = 50; // Fewer samples for job creation
    
    println!("Running {} samples...", samples);
    
    for i in 0..samples {
        let start = Instant::now();
        
        // Send message that triggers job
        ctx.ubl_client. send_message(SendMessageRequest {
            conversation_id: conversation_id.clone(),
            content: format!("Create task {}", i),
            idempotency_key: Some(format!("job_baseline_{}", i)),
        }).await?;
        
        // Wait for job creation
        tokio::time::sleep(Duration:: from_secs(5)).await;
        
        // Check if job was created
        let timeline = ctx.ubl_client. get_conversation_timeline(&conversation_id, None).await?;
        let has_job = timeline.items.iter().any(|item| item["item_type"] == "job_card");
        
        let duration = start.elapsed();
        
        if has_job {
            durations.push(duration);
            print!("‚úì");
        } else {
            print!("‚úó");
        }
        
        std::io::Write::flush(&mut std::io::stdout()).ok();
        tokio::time::sleep(Duration::from_secs(1)).await;
    }
    
    println!();
    
    if durations.is_empty() {
        println!("‚ö†Ô∏è  No jobs created, skipping baseline");
        return Ok(());
    }
    
    let metric = calculate_metric(&durations);
    
    println!("\nüìà Job Creation Performance:");
    println!("   p50: {:?}", metric.p50);
    println!("   p95: {:? }", metric.p95);
    println!("   p99: {: ?}", metric.p99);
    println!("   avg: {: ?}", metric.avg);
    println!("   Success rate: {}/{}", durations.len(), samples);
    
    assert!(metric.p95 < Duration::from_secs(10),
        "Job creation p95 too slow: {:?}", metric.p95);
    
    println!("‚úÖ Job creation baseline established");
    Ok(())
}

#[tokio::test]
async fn test_baseline_timeline_query_performance() -> Result<()> {
    println!("üìä Measuring Timeline Query Performance Baseline");
    
    let ctx = setup_golden_run().await?;
    let bootstrap = ctx. ubl_client.bootstrap("T.UBL").await?;
    let conversation_id = bootstrap.conversations.first()
        .and_then(|c| c["id"].as_str())
        .unwrap_or("conv_default")
        .to_string();
    
    let mut durations = Vec::new();
    let samples = 100;
    
    println!("Running {} samples...", samples);
    
    for i in 0..samples {
        let start = Instant::now();
        
        ctx.ubl_client.get_conversation_timeline(&conversation_id, None).await?;
        
        let duration = start.elapsed();
        durations.push(duration);
        
        if i % 10 == 0 {
            print!(".");
            std::io::Write::flush(&mut std::io::stdout()).ok();
        }
        
        tokio::time::sleep(Duration::from_millis(50)).await;
    }
    
    println!();
    
    let metric = calculate_metric(&durations);
    
    println!("\nüìà Timeline Query Performance:");
    println!("   p50: {:?}", metric. p50);
    println!("   p95: {:?}", metric.p95);
    println!("   p99: {:?}", metric.p99);
    println!("   avg: {:?}", metric.avg);
    
    assert!(metric.p95 < Duration::from_millis(100),
        "Timeline query p95 too slow: {:?}", metric.p95);
    
    println!("‚úÖ Timeline query baseline established");
    Ok(())
}

fn calculate_metric(durations: &[Duration]) -> PerformanceMetric {
    let mut sorted = durations.to_vec();
    sorted.sort();
    
    let len = sorted.len();
    let p50 = sorted[len * 50 / 100];
    let p95 = sorted[len * 95 / 100];
    let p99 = sorted[len * 99 / 100];
    
    let sum:  Duration = sorted.iter().sum();
    let avg = sum / len as u32;
    
    let min = *sorted.first().unwrap();
    let max = *sorted. last().unwrap();
    
    PerformanceMetric {
        p50,
        p95,
        p99,
        avg,
        min,
        max,
        samples: len,
    }
}

fn save_baseline(baseline: &PerformanceBaseline) -> Result<()> {
    let path = "../../reports/golden-run-baseline.json";
    let json = serde_json::to_string_pretty(baseline)?;
    std::fs::write(path, json)?;
    Ok(())
}